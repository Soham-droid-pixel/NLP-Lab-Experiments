{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F_6qhVz9aFdq"
      },
      "outputs": [],
      "source": [
        "!pip install spacy sklearn-crfsuite seqeval datasets transformers --quiet\n",
        "\n",
        "!pip install torch torchcrf --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3YAIXM7Ba7NW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import random\n",
        "import spacy\n",
        "import sklearn_crfsuite\n",
        "from datasets import load_dataset\n",
        "from seqeval.metrics import classification_report, f1_score\n",
        "from transformers import pipeline\n",
        "from spacy import displacy\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WPBQXz5ObQAn"
      },
      "outputs": [],
      "source": [
        "custom_sentences = [\n",
        "    \"Berlin hosted the Data Science Summit on 12/09/2024.\",\n",
        "    \"Bayern Munich signed Manuel Neuer in Munich.\",\n",
        "    \"TCS opened a new office in Pune.\",\n",
        "    \"Mercedes-Benz unveiled an EV in Stuttgart.\",\n",
        "    \"Rohit Sharma scored a century in Mumbai.\",\n",
        "    \"Google acquired DeepMind in London.\",\n",
        "    \"Elon Musk visited Bengaluru to discuss Tesla plans.\",\n",
        "    \"The Olympics will be held in Paris in 2024.\",\n",
        "    \"Apple announced the iPhone 15 in California.\",\n",
        "    \"Amazon opened a new warehouse in Hyderabad.\",\n",
        "    \"Cristiano Ronaldo joined Al Nassr in Riyadh.\",\n",
        "    \"Meta plans to build a data center in Singapore.\",\n",
        "    \"Neeraj Chopra won gold in Tokyo Olympics.\",\n",
        "    \"Infosys partnered with Microsoft in Seattle.\",\n",
        "    \"Wimbledon final was played in London.\",\n",
        "    \"Virat Kohli will captain the team in Delhi.\",\n",
        "    \"NASA launched Artemis mission from Florida.\",\n",
        "    \"The G20 Summit was hosted in New Delhi.\",\n",
        "    \"Manchester United signed Casemiro from Real Madrid.\",\n",
        "    \"ISRO launched Chandrayaan-3 from Sriharikota.\",\n",
        "    \"Novak Djokovic won the Australian Open in Melbourne.\",\n",
        "    \"Tesla opened its new Gigafactory in Texas.\",\n",
        "    \"Barcelona defeated Real Madrid in El Clasico.\",\n",
        "    \"Microsoft launched Copilot AI in New York.\",\n",
        "    \"Serena Williams retired after the US Open in New York.\",\n",
        "    \"Twitter rebranded to X Corp in San Francisco.\",\n",
        "    \"Liverpool signed Darwin Nunez from Benfica.\",\n",
        "    \"India won the Cricket World Cup in Ahmedabad.\",\n",
        "    \"OpenAI released GPT-5 in San Francisco.\",\n",
        "    \"Chelsea defeated Arsenal at Stamford Bridge in London.\",\n",
        "    \"Zomato acquired Blinkit in Gurugram.\",\n",
        "    \"The FIFA World Cup final was held in Doha, Qatar.\",\n",
        "    \"Sony launched PlayStation 6 in Tokyo.\",\n",
        "    \"Pakistan beat India in Lahore.\",\n",
        "    \"SpaceX launched Starship from Boca Chica, Texas.\",\n",
        "    \"Google opened a research lab in Zurich.\",\n",
        "    \"Amazon acquired MGM Studios in Los Angeles.\",\n",
        "    \"England won the Ashes in Sydney.\",\n",
        "    \"Byju's opened a new office in Dubai.\",\n",
        "    \"Ferrari unveiled a new model in Maranello, Italy.\",\n",
        "    \"Hyundai launched a new EV in Seoul.\",\n",
        "    \"Kylian Mbappe scored a hat-trick in Paris.\",\n",
        "    \"Intel opened a chip factory in Ohio.\",\n",
        "    \"Portugal won the Nations League in Lisbon.\",\n",
        "    \"Boeing unveiled a new aircraft in Seattle.\",\n",
        "    \"Nike opened a flagship store in Shanghai.\",\n",
        "    \"Uber launched flying taxis in Los Angeles.\",\n",
        "    \"Djokovic won Wimbledon in London.\",\n",
        "    \"Bharat Biotech announced a new vaccine in Hyderabad.\",\n",
        "    \"Germany won the Euro Cup in Berlin.\"\n",
        "]\n",
        "\n",
        "gold_labels = [\n",
        "    [(\"Berlin\", \"LOC\"), (\"Data Science Summit\", \"ORG\"), (\"12/09/2024\", \"DATE\")],\n",
        "    [(\"Bayern Munich\", \"ORG\"), (\"Manuel Neuer\", \"PER\"), (\"Munich\", \"LOC\")],\n",
        "    [(\"TCS\", \"ORG\"), (\"Pune\", \"LOC\")],\n",
        "    [(\"Mercedes-Benz\", \"ORG\"), (\"Stuttgart\", \"LOC\")],\n",
        "    [(\"Rohit Sharma\", \"PER\"), (\"Mumbai\", \"LOC\")],\n",
        "    [(\"Google\", \"ORG\"), (\"DeepMind\", \"ORG\"), (\"London\", \"LOC\")],\n",
        "    [(\"Elon Musk\", \"PER\"), (\"Bengaluru\", \"LOC\"), (\"Tesla\", \"ORG\")],\n",
        "    [(\"Olympics\", \"EVENT\"), (\"Paris\", \"LOC\"), (\"2024\", \"DATE\")],\n",
        "    [(\"Apple\", \"ORG\"), (\"iPhone 15\", \"PRODUCT\"), (\"California\", \"LOC\")],\n",
        "    [(\"Amazon\", \"ORG\"), (\"Hyderabad\", \"LOC\")],\n",
        "    [(\"Cristiano Ronaldo\", \"PER\"), (\"Al Nassr\", \"ORG\"), (\"Riyadh\", \"LOC\")],\n",
        "    [(\"Meta\", \"ORG\"), (\"Singapore\", \"LOC\")],\n",
        "    [(\"Neeraj Chopra\", \"PER\"), (\"Tokyo Olympics\", \"EVENT\")],\n",
        "    [(\"Infosys\", \"ORG\"), (\"Microsoft\", \"ORG\"), (\"Seattle\", \"LOC\")],\n",
        "    [(\"Wimbledon\", \"EVENT\"), (\"London\", \"LOC\")],\n",
        "    [(\"Virat Kohli\", \"PER\"), (\"Delhi\", \"LOC\")],\n",
        "    [(\"NASA\", \"ORG\"), (\"Artemis\", \"MISSION\"), (\"Florida\", \"LOC\")],\n",
        "    [(\"G20 Summit\", \"EVENT\"), (\"New Delhi\", \"LOC\")],\n",
        "    [(\"Manchester United\", \"ORG\"), (\"Casemiro\", \"PER\"), (\"Real Madrid\", \"ORG\")],\n",
        "    [(\"ISRO\", \"ORG\"), (\"Chandrayaan-3\", \"MISSION\"), (\"Sriharikota\", \"LOC\")],\n",
        "    [(\"Novak Djokovic\", \"PER\"), (\"Australian Open\", \"EVENT\"), (\"Melbourne\", \"LOC\")],\n",
        "    [(\"Tesla\", \"ORG\"), (\"Gigafactory\", \"FACILITY\"), (\"Texas\", \"LOC\")],\n",
        "    [(\"Barcelona\", \"ORG\"), (\"Real Madrid\", \"ORG\"), (\"El Clasico\", \"EVENT\")],\n",
        "    [(\"Microsoft\", \"ORG\"), (\"Copilot AI\", \"PRODUCT\"), (\"New York\", \"LOC\")],\n",
        "    [(\"Serena Williams\", \"PER\"), (\"US Open\", \"EVENT\"), (\"New York\", \"LOC\")],\n",
        "    [(\"Twitter\", \"ORG\"), (\"X Corp\", \"ORG\"), (\"San Francisco\", \"LOC\")],\n",
        "    [(\"Liverpool\", \"ORG\"), (\"Darwin Nunez\", \"PER\"), (\"Benfica\", \"ORG\")],\n",
        "    [(\"India\", \"LOC\"), (\"Cricket World Cup\", \"EVENT\"), (\"Ahmedabad\", \"LOC\")],\n",
        "    [(\"OpenAI\", \"ORG\"), (\"GPT-5\", \"PRODUCT\"), (\"San Francisco\", \"LOC\")],\n",
        "    [(\"Chelsea\", \"ORG\"), (\"Arsenal\", \"ORG\"), (\"Stamford Bridge\", \"FACILITY\"), (\"London\", \"LOC\")],\n",
        "    [(\"Zomato\", \"ORG\"), (\"Blinkit\", \"ORG\"), (\"Gurugram\", \"LOC\")],\n",
        "    [(\"FIFA World Cup\", \"EVENT\"), (\"Doha\", \"LOC\"), (\"Qatar\", \"LOC\")],\n",
        "    [(\"Sony\", \"ORG\"), (\"PlayStation 6\", \"PRODUCT\"), (\"Tokyo\", \"LOC\")],\n",
        "    [(\"Pakistan\", \"LOC\"), (\"India\", \"LOC\"), (\"Lahore\", \"LOC\")],\n",
        "    [(\"SpaceX\", \"ORG\"), (\"Starship\", \"PRODUCT\"), (\"Boca Chica\", \"LOC\"), (\"Texas\", \"LOC\")],\n",
        "    [(\"Google\", \"ORG\"), (\"Zurich\", \"LOC\")],\n",
        "    [(\"Amazon\", \"ORG\"), (\"MGM Studios\", \"ORG\"), (\"Los Angeles\", \"LOC\")],\n",
        "    [(\"England\", \"LOC\"), (\"Ashes\", \"EVENT\"), (\"Sydney\", \"LOC\")],\n",
        "    [(\"Byju's\", \"ORG\"), (\"Dubai\", \"LOC\")],\n",
        "    [(\"Ferrari\", \"ORG\"), (\"Maranello\", \"LOC\"), (\"Italy\", \"LOC\")],\n",
        "    [(\"Hyundai\", \"ORG\"), (\"Seoul\", \"LOC\")],\n",
        "    [(\"Kylian Mbappe\", \"PER\"), (\"Paris\", \"LOC\")],\n",
        "    [(\"Intel\", \"ORG\"), (\"Ohio\", \"LOC\")],\n",
        "    [(\"Portugal\", \"LOC\"), (\"Nations League\", \"EVENT\"), (\"Lisbon\", \"LOC\")],\n",
        "    [(\"Boeing\", \"ORG\"), (\"Seattle\", \"LOC\")],\n",
        "    [(\"Nike\", \"ORG\"), (\"Shanghai\", \"LOC\")],\n",
        "    [(\"Uber\", \"ORG\"), (\"Los Angeles\", \"LOC\")],\n",
        "    [(\"Novak Djokovic\", \"PER\"), (\"Wimbledon\", \"EVENT\"), (\"London\", \"LOC\")],\n",
        "    [(\"Bharat Biotech\", \"ORG\"), (\"Hyderabad\", \"LOC\")],\n",
        "    [(\"Germany\", \"LOC\"), (\"Euro Cup\", \"EVENT\"), (\"Berlin\", \"LOC\")]\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQUJZuvWbjgF",
        "outputId": "86ab209b-305e-4735-ef39-6d525eb245d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule-based NER example:\n",
            "Berlin hosted the Data Science Summit on 12/09/2024. -> [('12/09/2024', 'DATE'), ('Berlin', 'LOC'), ('Data Science Summit', 'MISC')]\n",
            "Bayern Munich signed Manuel Neuer in Munich. -> [('Munich', 'LOC'), ('Bayern Munich', 'ORG'), ('Manuel Neuer', 'MISC')]\n",
            "TCS opened a new office in Pune. -> [('Pune', 'LOC')]\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# 2️⃣ RULE-BASED NER\n",
        "# -------------------------------\n",
        "cities = [\"Berlin\", \"Munich\", \"Pune\", \"Stuttgart\", \"Mumbai\", \"London\", \"Bengaluru\", \"Paris\", \"California\",\n",
        "          \"Hyderabad\", \"Riyadh\", \"Singapore\", \"Tokyo\", \"Seattle\", \"Delhi\", \"Florida\", \"New Delhi\", \"Madrid\", \"Sriharikota\",\n",
        "          \"Melbourne\", \"Texas\", \"New York\", \"San Francisco\", \"Ahmedabad\", \"Gurugram\", \"Doha\", \"Qatar\", \"Lahore\",\n",
        "          \"Boca Chica\", \"Zurich\", \"Los Angeles\", \"Sydney\", \"Dubai\", \"Maranello\", \"Italy\", \"Seoul\", \"Ohio\", \"Lisbon\", \"Shanghai\"]\n",
        "\n",
        "teams = [\"Bayern Munich\", \"Manchester United\", \"Real Madrid\", \"Al Nassr\", \"India\", \"Barcelona\", \"Liverpool\", \"Pakistan\", \"Chelsea\", \"Arsenal\"]\n",
        "\n",
        "def rule_based_ner(sentence):\n",
        "    entities = []\n",
        "    for match in re.finditer(r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\", sentence):\n",
        "        entities.append((match.group(), \"DATE\"))\n",
        "    for city in cities:\n",
        "        if city in sentence:\n",
        "            entities.append((city, \"LOC\"))\n",
        "    for team in teams:\n",
        "        if team in sentence:\n",
        "            entities.append((team, \"ORG\"))\n",
        "    for match in re.finditer(r\"\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\b\", sentence):\n",
        "        token = match.group()\n",
        "        if token not in [c for c, _ in entities]:\n",
        "            entities.append((token, \"MISC\"))\n",
        "    return entities\n",
        "\n",
        "print(\"Rule-based NER example:\")\n",
        "for s in custom_sentences[:3]:\n",
        "    print(s, \"->\", rule_based_ner(s))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jAQaxh1Nb2h0",
        "outputId": "1158d06e-d414-47c4-d6fd-2e618a886c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "spaCy NER example:\n",
            "Berlin GPE\n",
            "the Data Science Summit ORG\n",
            "12/09/2024 DATE\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Berlin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " hosted \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Data Science Summit\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    12/09/2024\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# 3️⃣ spaCy NER\n",
        "# -------------------------------\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "print(\"\\nspaCy NER example:\")\n",
        "doc = nlp(custom_sentences[0])\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cIqhsC-GgqIw"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def train_hmm(sentences, tags):\n",
        "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "    tag_counts = defaultdict(int)\n",
        "\n",
        "    for words, tgs in zip(sentences, tags):\n",
        "        prev_tag = \"<START>\"\n",
        "        for w, tg in zip(words, tgs):\n",
        "            transition_counts[prev_tag][tg] += 1\n",
        "            emission_counts[tg][w] += 1\n",
        "            tag_counts[tg] += 1\n",
        "            prev_tag = tg\n",
        "        transition_counts[prev_tag][\"<END>\"] += 1\n",
        "\n",
        "    # Convert to probabilities\n",
        "    transition_probs = {t: {t2: c/sum(d.values()) for t2, c in d.items()} for t, d in transition_counts.items()}\n",
        "    emission_probs = {t: {w: c/sum(d.values()) for w, c in d.items()} for t, d in emission_counts.items()}\n",
        "\n",
        "    return transition_probs, emission_probs, list(tag_counts.keys())\n",
        "\n",
        "def viterbi(words, transition_probs, emission_probs, tags):\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "\n",
        "    for t in tags:\n",
        "        V[0][t] = np.log(transition_probs.get(\"<START>\", {}).get(t, 1e-6)) + np.log(emission_probs.get(t, {}).get(words[0], 1e-6))\n",
        "        path[t] = [t]\n",
        "\n",
        "    for i in range(1, len(words)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "        for t in tags:\n",
        "            (prob, state) = max(\n",
        "                (V[i-1][pt] + np.log(transition_probs.get(pt, {}).get(t, 1e-6)) + np.log(emission_probs.get(t, {}).get(words[i], 1e-6)), pt)\n",
        "                for pt in tags\n",
        "            )\n",
        "            V[i][t] = prob\n",
        "            new_path[t] = path[state] + [t]\n",
        "        path = new_path\n",
        "\n",
        "    (prob, state) = max((V[len(words)-1][t] + np.log(transition_probs.get(t, {}).get(\"<END>\", 1e-6)), t) for t in tags)\n",
        "    return path[state]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "EC_l2blkSNVi",
        "outputId": "f291fad9-1d56-4a58-9c86-20d0123a8e7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e63cbe2-d753-4edb-9678-fc996035c04f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e63cbe2-d753-4edb-9678-fc996035c04f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded_files=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwLdwnEQhnLQ",
        "outputId": "6fea7b32-f95a-437e-989f-56de51461e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.8.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets seqeval sklearn-crfsuite spacy==3.7.2 --quiet\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfzMA3KthzEg",
        "outputId": "d8b3d66f-14d7-4d38-b716-078d25e13210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], ['Peter', 'Blackburn']]\n",
            "[['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'], ['B-PER', 'I-PER']]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datasets import DatasetDict, Dataset\n",
        "\n",
        "# Function to load JSON Lines\n",
        "def load_jsonl(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "# Load dataset files\n",
        "train_data = load_jsonl(\"/content/train.json\")\n",
        "test_data = load_jsonl(\"/content/test.json\")\n",
        "valid_data = load_jsonl(\"/content/valid.json\")\n",
        "\n",
        "# Load label file\n",
        "with open(\"/content/label.json\") as f:\n",
        "    labels = json.load(f)\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_list(train_data),\n",
        "    \"test\": Dataset.from_list(test_data),\n",
        "    \"validation\": Dataset.from_list(valid_data)\n",
        "})\n",
        "\n",
        "# Extract small subset for speed\n",
        "train_tokens = [item[\"tokens\"] for item in dataset[\"train\"]][:100]\n",
        "train_tags = [item[\"tags\"] for item in dataset[\"train\"]][:100]\n",
        "test_tokens = [item[\"tokens\"] for item in dataset[\"test\"]][:50]\n",
        "test_tags = [item[\"tags\"] for item in dataset[\"test\"]][:50]\n",
        "\n",
        "# Determine label mapping format\n",
        "if isinstance(labels, list):\n",
        "    # Case 1: List of labels\n",
        "    id2label = {i: label for i, label in enumerate(labels)}\n",
        "elif all(k.isdigit() for k in labels.keys()):\n",
        "    # Case 2: Dict with string numbers as keys\n",
        "    id2label = {int(k): v for k, v in labels.items()}\n",
        "elif all(isinstance(v, int) for v in labels.values()):\n",
        "    # Case 3: Dict with label names as keys\n",
        "    id2label = {v: k for k, v in labels.items()}\n",
        "else:\n",
        "    raise ValueError(\"Unrecognized label.json format\")\n",
        "\n",
        "# Map tag IDs to label strings\n",
        "train_tags = [[id2label[tag] for tag in seq] for seq in train_tags]\n",
        "test_tags = [[id2label[tag] for tag in seq] for seq in test_tags]\n",
        "\n",
        "print(train_tokens[:2])\n",
        "print(train_tags[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2CjrWwJTJif",
        "outputId": "ddd4e7b2-92af-4ad4-fb95-3754dbe115b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.67      0.28      0.39        43\n",
            "        MISC       1.00      0.44      0.62        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.88      0.72      0.79        83\n",
            "\n",
            "   micro avg       0.77      0.55      0.64       146\n",
            "   macro avg       0.64      0.36      0.45       146\n",
            "weighted avg       0.82      0.55      0.64       146\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CRF\n",
        "import sklearn_crfsuite\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "# Feature extractor for one token\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'prefix2': word[:2],\n",
        "        'prefix3': word[:3],\n",
        "        'suffix2': word[-2:],\n",
        "        'suffix3': word[-3:]\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True  # Beginning of sentence\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True  # End of sentence\n",
        "\n",
        "    return features\n",
        "\n",
        "# Convert sentences to feature dicts\n",
        "X_train = [[word2features(s, i) for i in range(len(s))] for s in train_tokens]\n",
        "y_train = train_tags\n",
        "X_test = [[word2features(s, i) for i in range(len(s))] for s in test_tokens]\n",
        "y_test = test_tags\n",
        "\n",
        "# Train CRF\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,  # L1 reg\n",
        "    c2=0.1,  # L2 reg\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = crf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ3uY52FUw62",
        "outputId": "63ad9f76-e63a-4a2f-d591-c38fc33445ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       1.00      0.23      0.38        43\n",
            "        MISC       1.00      0.44      0.62        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00        83\n",
            "\n",
            "   micro avg       1.00      0.12      0.22       146\n",
            "   macro avg       0.50      0.17      0.25       146\n",
            "weighted avg       0.42      0.12      0.19       146\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#HMM:\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def train_hmm(sentences, tags):\n",
        "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "    tag_counts = defaultdict(int)\n",
        "\n",
        "    for words, tgs in zip(sentences, tags):\n",
        "        prev_tag = \"<START>\"\n",
        "        for w, tg in zip(words, tgs):\n",
        "            transition_counts[prev_tag][tg] += 1\n",
        "            emission_counts[tg][w] += 1\n",
        "            tag_counts[tg] += 1\n",
        "            prev_tag = tg\n",
        "        transition_counts[prev_tag][\"<END>\"] += 1\n",
        "\n",
        "    transition_probs = {t: {t2: c/sum(d.values()) for t2, c in d.items()}\n",
        "                        for t, d in transition_counts.items()}\n",
        "    emission_probs = {t: {w: c/sum(d.values()) for w, c in d.items()}\n",
        "                      for t, d in emission_counts.items()}\n",
        "\n",
        "    return transition_probs, emission_probs, list(tag_counts.keys())\n",
        "\n",
        "def viterbi(words, transition_probs, emission_probs, tags):\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "    for t in tags:\n",
        "        V[0][t] = np.log(transition_probs.get(\"<START>\", {}).get(t, 1e-6)) + \\\n",
        "                  np.log(emission_probs.get(t, {}).get(words[0], 1e-6))\n",
        "        path[t] = [t]\n",
        "\n",
        "    for i in range(1, len(words)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "        for t in tags:\n",
        "            (prob, state) = max(\n",
        "                (V[i-1][pt] + np.log(transition_probs.get(pt, {}).get(t, 1e-6)) +\n",
        "                 np.log(emission_probs.get(t, {}).get(words[i], 1e-6)), pt)\n",
        "                for pt in tags\n",
        "            )\n",
        "            V[i][t] = prob\n",
        "            new_path[t] = path[state] + [t]\n",
        "        path = new_path\n",
        "\n",
        "    (prob, state) = max(\n",
        "        (V[-1][t] + np.log(transition_probs.get(t, {}).get(\"<END>\", 1e-6)), t)\n",
        "        for t in tags\n",
        "    )\n",
        "    return path[state]\n",
        "\n",
        "# Train and evaluate\n",
        "transition_probs, emission_probs, tag_list = train_hmm(train_tokens, train_tags)\n",
        "pred_tags_hmm = [viterbi(sent, transition_probs, emission_probs, tag_list) for sent in test_tokens]\n",
        "\n",
        "print(classification_report(test_tags, pred_tags_hmm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wJAkGazU-dc",
        "outputId": "18c8697a-1518-4d2a-c978-4a2da37da9aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Berlin -> LOC (score: 0.9998)\n",
            "Data Science Summit -> MISC (score: 0.9977)\n",
            "Inference time: 0.3137 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers --quiet\n",
        "\n",
        "from transformers import pipeline\n",
        "import time\n",
        "\n",
        "# Load pipeline\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"Berlin hosted the Data Science Summit on 12/09/2024.\"\n",
        "\n",
        "# Time inference\n",
        "start_time = time.time()\n",
        "entities = ner_pipeline(sentence)\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "# Print results\n",
        "for ent in entities:\n",
        "    print(f\"{ent['word']} -> {ent['entity_group']} (score: {ent['score']:.4f})\")\n",
        "print(f\"Inference time: {elapsed_time:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc4OeULHX1gq",
        "outputId": "6f1a0eae-1c27-495e-eab0-2bceaf940919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch --quiet\n",
        "!pip install git+https://github.com/kmkurn/pytorch-crf.git --quiet\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0doLzMQzVMT3",
        "outputId": "2fad158b-9360-409c-b5cf-c770bfcac0ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Loading GloVe vectors...\n",
            "Epoch 1 Loss: 31.9060 | Test Macro F1: 0.0275\n",
            "Epoch 2 Loss: 24.2866 | Test Macro F1: 0.0204\n",
            "Epoch 3 Loss: 14.8689 | Test Macro F1: 0.0205\n",
            "Epoch 4 Loss: 11.4342 | Test Macro F1: 0.0167\n",
            "Epoch 5 Loss: 12.7844 | Test Macro F1: 0.0231\n",
            "Epoch 6 Loss: 11.1784 | Test Macro F1: 0.0294\n",
            "Epoch 7 Loss: 9.5986 | Test Macro F1: 0.0208\n",
            "Epoch 8 Loss: 9.3545 | Test Macro F1: 0.0205\n",
            "Epoch 9 Loss: 8.7823 | Test Macro F1: 0.0217\n",
            "Epoch 10 Loss: 8.2198 | Test Macro F1: 0.0221\n",
            "Epoch 11 Loss: 9.6734 | Test Macro F1: 0.0145\n",
            "Epoch 12 Loss: 8.6714 | Test Macro F1: 0.0192\n",
            "Epoch 13 Loss: 7.3518 | Test Macro F1: 0.0281\n",
            "Epoch 14 Loss: 7.6544 | Test Macro F1: 0.0500\n",
            "Epoch 15 Loss: 6.8247 | Test Macro F1: 0.0522\n",
            "Epoch 16 Loss: 6.7938 | Test Macro F1: 0.0530\n",
            "Epoch 17 Loss: 6.1416 | Test Macro F1: 0.0463\n",
            "Epoch 18 Loss: 6.0993 | Test Macro F1: 0.0433\n",
            "Epoch 19 Loss: 5.4954 | Test Macro F1: 0.0404\n",
            "Epoch 20 Loss: 5.5408 | Test Macro F1: 0.0366\n",
            "Epoch 21 Loss: 5.4866 | Test Macro F1: 0.0328\n",
            "Epoch 22 Loss: 4.5961 | Test Macro F1: 0.0338\n",
            "Epoch 23 Loss: 4.0641 | Test Macro F1: 0.0323\n",
            "Epoch 24 Loss: 3.7949 | Test Macro F1: 0.0330\n",
            "Epoch 25 Loss: 3.4349 | Test Macro F1: 0.0338\n",
            "Epoch 26 Loss: 3.0822 | Test Macro F1: 0.0371\n",
            "Epoch 27 Loss: 2.7332 | Test Macro F1: 0.0389\n",
            "Epoch 28 Loss: 2.6999 | Test Macro F1: 0.0386\n",
            "Epoch 29 Loss: 2.5676 | Test Macro F1: 0.0387\n",
            "Epoch 30 Loss: 2.0995 | Test Macro F1: 0.0409\n",
            "\n",
            "Final Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.09      0.70      0.16        43\n",
            "        MISC       0.00      0.00      0.00        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00        83\n",
            "\n",
            "   micro avg       0.05      0.21      0.08       146\n",
            "   macro avg       0.02      0.17      0.04       146\n",
            "weighted avg       0.03      0.21      0.05       146\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from seqeval.metrics import classification_report\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "\n",
        "# ===== Device =====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ===== Create vocab =====\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "for sent in train_tokens:\n",
        "    for w in sent:\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = len(word2idx)\n",
        "\n",
        "tag2idx = {tag: i for i, tag in enumerate(sorted({t for seq in train_tags for t in seq}))}\n",
        "idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
        "\n",
        "# ===== Load pretrained GloVe (100d) =====\n",
        "print(\"Loading GloVe vectors...\")\n",
        "glove_vectors = api.load(\"glove-wiki-gigaword-100\")\n",
        "embedding_dim = glove_vectors.vector_size\n",
        "\n",
        "embedding_matrix = np.zeros((len(word2idx), embedding_dim))\n",
        "for word, idx in word2idx.items():\n",
        "    if word in glove_vectors:\n",
        "        embedding_matrix[idx] = glove_vectors[word]\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
        "\n",
        "# ===== Dataset =====\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, tokens, tags):\n",
        "        self.tokens = tokens\n",
        "        self.tags = tags\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "    def __getitem__(self, idx):\n",
        "        words = [word2idx.get(w, 1) for w in self.tokens[idx]]\n",
        "        labels = [tag2idx[t] for t in self.tags[idx]]\n",
        "        return torch.tensor(words, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# ===== Collate with padding =====\n",
        "def collate_fn(batch):\n",
        "    words, labels = zip(*batch)\n",
        "    words_padded = pad_sequence(words, batch_first=True, padding_value=word2idx[\"<PAD>\"])\n",
        "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=-1)  # keep -1 for padding\n",
        "    return words_padded, labels_padded\n",
        "\n",
        "# ===== DataLoader =====\n",
        "train_dataset = NERDataset(train_tokens[:5000], train_tags[:5000])\n",
        "test_dataset = NERDataset(test_tokens, test_tags)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn)\n",
        "\n",
        "# ===== Model =====\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim=100, hidden_dim=128, embedding_matrix=None):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx[\"<PAD>\"])\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float))\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        self.crf = CRF(tagset_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        emb = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(emb)\n",
        "        emissions = self.hidden2tag(lstm_out)\n",
        "        if tags is not None:\n",
        "            return -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=mask)\n",
        "\n",
        "# ===== Initialize model =====\n",
        "model = BiLSTM_CRF(len(word2idx), len(tag2idx), embedding_dim=embedding_dim,\n",
        "                   embedding_matrix=embedding_matrix).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ===== Training =====\n",
        "for epoch in range(30):  # train longer for better convergence\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for words, labels in train_loader:\n",
        "        words, labels = words.to(device), labels.to(device)\n",
        "        mask = labels != -1  # True where token is not padding\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(words, labels, mask=mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Evaluate on test set each epoch\n",
        "    model.eval()\n",
        "    pred_tags, true_tags = [], []\n",
        "    with torch.no_grad():\n",
        "        for words, labels in test_loader:\n",
        "            words, labels = words.to(device), labels.to(device)\n",
        "            mask = labels != -1\n",
        "            preds = model(words, mask=mask)\n",
        "            pred_tags.append([idx2tag[i] for i in preds[0]])\n",
        "            true_tags.append([idx2tag[i.item()] for i in labels[0] if i.item() != -1])\n",
        "    f1 = classification_report(true_tags, pred_tags, digits=4, output_dict=True)[\"macro avg\"][\"f1-score\"]\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f} | Test Macro F1: {f1:.4f}\")\n",
        "\n",
        "# ===== Final evaluation =====\n",
        "print(\"\\nFinal Classification Report:\")\n",
        "print(classification_report(true_tags, pred_tags))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oitkBZXLVVZx",
        "outputId": "12cf1a20-a362-4621-dfc5-03cace06d1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Rule-based ===\n",
            "Precision: 0.1074\n",
            "Recall:    0.1096\n",
            "F1-score:  0.1085\n",
            "Inference time: 0.0024 sec\n",
            "\n",
            "Detailed report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       1.00      0.05      0.09        43\n",
            "        MISC       0.10      0.78      0.17        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00        83\n",
            "\n",
            "   micro avg       0.11      0.11      0.11       146\n",
            "   macro avg       0.27      0.21      0.06       146\n",
            "weighted avg       0.31      0.11      0.05       146\n",
            "\n",
            "Sample Misclassifications (Rule-based):\n",
            "TOKENS: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "TRUE:   ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['Nadim', 'Ladki']\n",
            "TRUE:   ['B-PER', 'I-PER']\n",
            "PRED:   ['B-MISC', 'I-MISC']\n",
            "\n",
            "TOKENS: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "TRUE:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "PRED:   ['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O']\n",
            "\n",
            "TOKENS: ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'B-MISC', 'O']\n",
            "\n",
            "TOKENS: ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
            "TRUE:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "PRED:   ['B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O']\n",
            "\n",
            "\n",
            "=== spaCy ===\n",
            "Precision: 0.0052\n",
            "Recall:    0.0068\n",
            "F1-score:  0.0059\n",
            "Inference time: 0.4827 sec\n",
            "\n",
            "Detailed report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    CARDINAL       0.00      0.00      0.00         0\n",
            "        DATE       0.00      0.00      0.00         0\n",
            "       EVENT       0.00      0.00      0.00         0\n",
            "         GPE       0.00      0.00      0.00         0\n",
            "         LOC       0.00      0.00      0.00        43\n",
            "        MISC       0.00      0.00      0.00        18\n",
            "        NORP       0.00      0.00      0.00         0\n",
            "     ORDINAL       0.00      0.00      0.00         0\n",
            "         ORG       0.08      0.50      0.13         2\n",
            "         PER       0.00      0.00      0.00        83\n",
            "      PERSON       0.00      0.00      0.00         0\n",
            "        TIME       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.01      0.01      0.01       146\n",
            "   macro avg       0.01      0.04      0.01       146\n",
            "weighted avg       0.00      0.01      0.00       146\n",
            "\n",
            "Sample Misclassifications (spaCy):\n",
            "TOKENS: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "TRUE:   ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
            "\n",
            "TOKENS: ['Nadim', 'Ladki']\n",
            "TRUE:   ['B-PER', 'I-PER']\n",
            "PRED:   ['B-GPE', 'O']\n",
            "\n",
            "TOKENS: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "TRUE:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "PRED:   ['B-ORG', 'O', 'B-GPE', 'I-GPE', 'I-GPE', 'B-DATE']\n",
            "\n",
            "TOKENS: ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['B-GPE', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'I-EVENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-DATE', 'O']\n",
            "\n",
            "TOKENS: ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
            "TRUE:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "PRED:   ['O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O']\n",
            "\n",
            "\n",
            "=== CRF ===\n",
            "Precision: 0.7692\n",
            "Recall:    0.5479\n",
            "F1-score:  0.6400\n",
            "Inference time: 0.0105 sec\n",
            "\n",
            "Detailed report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.67      0.28      0.39        43\n",
            "        MISC       1.00      0.44      0.62        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.88      0.72      0.79        83\n",
            "\n",
            "   micro avg       0.77      0.55      0.64       146\n",
            "   macro avg       0.64      0.36      0.45       146\n",
            "weighted avg       0.82      0.55      0.64       146\n",
            "\n",
            "Sample Misclassifications (CRF):\n",
            "TOKENS: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "TRUE:   ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "TRUE:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "PRED:   ['O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O']\n",
            "\n",
            "TOKENS: ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
            "TRUE:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "PRED:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['China', 'controlled', 'most', 'of', 'the', 'match', 'and', 'saw', 'several', 'chances', 'missed', 'until', 'the', '78th', 'minute', 'when', 'Uzbek', 'striker', 'Igor', 'Shkvyrin', 'took', 'advantage', 'of', 'a', 'misdirected', 'defensive', 'header', 'to', 'lob', 'the', 'ball', 'over', 'the', 'advancing', 'Chinese', 'keeper', 'and', 'into', 'an', 'empty', 'net', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "=== HMM ===\n",
            "Precision: 1.0000\n",
            "Recall:    0.1233\n",
            "F1-score:  0.2195\n",
            "Inference time: 0.2205 sec\n",
            "\n",
            "Detailed report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       1.00      0.23      0.38        43\n",
            "        MISC       1.00      0.44      0.62        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00        83\n",
            "\n",
            "   micro avg       1.00      0.12      0.22       146\n",
            "   macro avg       0.50      0.17      0.25       146\n",
            "weighted avg       0.42      0.12      0.19       146\n",
            "\n",
            "Sample Misclassifications (HMM):\n",
            "TOKENS: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "TRUE:   ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['Nadim', 'Ladki']\n",
            "TRUE:   ['B-PER', 'I-PER']\n",
            "PRED:   ['O', 'O']\n",
            "\n",
            "TOKENS: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "TRUE:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
            "TRUE:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "PRED:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "=== Transformer (BERT) ===\n",
            "Precision: 0.9545\n",
            "Recall:    0.5753\n",
            "F1-score:  0.7179\n",
            "Inference time: 8.9502 sec\n",
            "\n",
            "Detailed report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       1.00      0.84      0.91        43\n",
            "        MISC       0.88      0.83      0.86        18\n",
            "         ORG       0.33      0.50      0.40         2\n",
            "         PER       1.00      0.39      0.56        83\n",
            "\n",
            "   micro avg       0.95      0.58      0.72       146\n",
            "   macro avg       0.80      0.64      0.68       146\n",
            "weighted avg       0.98      0.58      0.70       146\n",
            "\n",
            "Sample Misclassifications (BERT):\n",
            "TOKENS: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "TRUE:   ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['Nadim', 'Ladki']\n",
            "TRUE:   ['B-PER', 'I-PER']\n",
            "PRED:   ['O', 'O']\n",
            "\n",
            "TOKENS: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "TRUE:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "PRED:   ['O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "\n",
            "TOKENS: ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "TOKENS: ['Oleg', 'Shatskiku', 'made', 'sure', 'of', 'the', 'win', 'in', 'injury', 'time', ',', 'hitting', 'an', 'unstoppable', 'left', 'foot', 'shot', 'from', 'just', 'outside', 'the', 'area', '.']\n",
            "TRUE:   ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "\n",
            "=== BiLSTM-CRF ===\n",
            "Precision: 0.0515\n",
            "Recall:    0.2055\n",
            "F1-score:  0.0824\n",
            "Inference time: 0.1875 sec\n",
            "\n",
            "Detailed report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.09      0.70      0.16        43\n",
            "        MISC       0.00      0.00      0.00        18\n",
            "         ORG       0.00      0.00      0.00         2\n",
            "         PER       0.00      0.00      0.00        83\n",
            "\n",
            "   micro avg       0.05      0.21      0.08       146\n",
            "   macro avg       0.02      0.17      0.04       146\n",
            "weighted avg       0.03      0.21      0.05       146\n",
            "\n",
            "Sample Misclassifications (BiLSTM-CRF):\n",
            "TOKENS: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "TRUE:   ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['B-LOC', 'O', 'B-ORG', 'B-ORG', 'B-ORG', 'B-LOC', 'O', 'B-ORG', 'B-ORG', 'B-LOC', 'B-LOC', 'O']\n",
            "\n",
            "TOKENS: ['Nadim', 'Ladki']\n",
            "TRUE:   ['B-PER', 'I-PER']\n",
            "PRED:   ['B-LOC', 'B-LOC']\n",
            "\n",
            "TOKENS: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "TRUE:   ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "PRED:   ['B-LOC', 'O', 'B-ORG', 'B-ORG', 'B-LOC', 'B-LOC']\n",
            "\n",
            "TOKENS: ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "TRUE:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "PRED:   ['B-ORG', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'B-ORG', 'B-ORG', 'B-LOC', 'O', 'O', 'B-ORG', 'B-ORG', 'B-ORG', 'B-ORG', 'B-LOC', 'O', 'O', 'B-ORG', 'B-ORG', 'B-ORG', 'B-LOC', 'O', 'B-LOC', 'O']\n",
            "\n",
            "TOKENS: ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
            "TRUE:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
            "PRED:   ['O', 'B-LOC', 'B-LOC', 'O', 'B-ORG', 'B-ORG', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-ORG', 'B-ORG', 'B-LOC', 'O', 'B-ORG', 'B-LOC', 'O']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# =============================\n",
        "# BIO Conversion Helper\n",
        "# =============================\n",
        "def to_bio_tags(tokens, entities):\n",
        "    \"\"\"\n",
        "    Convert a list of entities into BIO tags for the given tokens.\n",
        "    entities: list of (entity_text, entity_label) tuples\n",
        "    \"\"\"\n",
        "    tags = [\"O\"] * len(tokens)\n",
        "    for ent_text, ent_label in entities:\n",
        "        ent_tokens = ent_text.split()\n",
        "        for i in range(len(tokens)):\n",
        "            if tokens[i:i+len(ent_tokens)] == ent_tokens:\n",
        "                tags[i] = f\"B-{ent_label}\"\n",
        "                for j in range(1, len(ent_tokens)):\n",
        "                    tags[i+j] = f\"I-{ent_label}\"\n",
        "    return tags\n",
        "\n",
        "# =============================\n",
        "# Evaluation Helper Functions\n",
        "# =============================\n",
        "def evaluate_method(name, y_true, y_pred, train_time=None, inference_time=None):\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"F1-score:  {f1_score(y_true, y_pred):.4f}\")\n",
        "    if train_time is not None:\n",
        "        print(f\"Training time: {train_time:.4f} sec\")\n",
        "    if inference_time is not None:\n",
        "        print(f\"Inference time: {inference_time:.4f} sec\")\n",
        "    print(\"\\nDetailed report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def get_misclassifications(y_true, y_pred, tokens, n=5):\n",
        "    errors = []\n",
        "    for i, (true_seq, pred_seq, tok_seq) in enumerate(zip(y_true, y_pred, tokens)):\n",
        "        if true_seq != pred_seq:\n",
        "            errors.append((tok_seq, true_seq, pred_seq))\n",
        "        if len(errors) >= n:\n",
        "            break\n",
        "    return errors\n",
        "\n",
        "# =============================\n",
        "# 1️⃣ Rule-based Evaluation (BIO)\n",
        "# =============================\n",
        "start_time = time.time()\n",
        "rule_preds = []\n",
        "for sent in test_tokens:\n",
        "    ents = rule_based_ner(\" \".join(sent))  # returns [(text, label), ...]\n",
        "    pred_tags = to_bio_tags(sent, ents)\n",
        "    rule_preds.append(pred_tags)\n",
        "rule_inference_time = time.time() - start_time\n",
        "\n",
        "evaluate_method(\"Rule-based\", test_tags, rule_preds, inference_time=rule_inference_time)\n",
        "print(\"Sample Misclassifications (Rule-based):\")\n",
        "for tok, true, pred in get_misclassifications(test_tags, rule_preds, test_tokens):\n",
        "    print(\"TOKENS:\", tok)\n",
        "    print(\"TRUE:  \", true)\n",
        "    print(\"PRED:  \", pred)\n",
        "    print()\n",
        "\n",
        "# =============================\n",
        "# 2️⃣ spaCy Evaluation (BIO)\n",
        "# =============================\n",
        "start_time = time.time()\n",
        "spacy_preds = []\n",
        "for sent in test_tokens:\n",
        "    doc = nlp(\" \".join(sent))\n",
        "    ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    pred_tags = to_bio_tags(sent, ents)\n",
        "    spacy_preds.append(pred_tags)\n",
        "spacy_inference_time = time.time() - start_time\n",
        "\n",
        "evaluate_method(\"spaCy\", test_tags, spacy_preds, inference_time=spacy_inference_time)\n",
        "print(\"Sample Misclassifications (spaCy):\")\n",
        "for tok, true, pred in get_misclassifications(test_tags, spacy_preds, test_tokens):\n",
        "    print(\"TOKENS:\", tok)\n",
        "    print(\"TRUE:  \", true)\n",
        "    print(\"PRED:  \", pred)\n",
        "    print()\n",
        "\n",
        "# =============================\n",
        "# 3️⃣ CRF Evaluation (unchanged)\n",
        "# =============================\n",
        "start_time = time.time()\n",
        "crf_preds = crf.predict(X_test)\n",
        "crf_inference_time = time.time() - start_time\n",
        "\n",
        "evaluate_method(\"CRF\", y_test, crf_preds, inference_time=crf_inference_time)\n",
        "print(\"Sample Misclassifications (CRF):\")\n",
        "for tok, true, pred in get_misclassifications(y_test, crf_preds, test_tokens):\n",
        "    print(\"TOKENS:\", tok)\n",
        "    print(\"TRUE:  \", true)\n",
        "    print(\"PRED:  \", pred)\n",
        "    print()\n",
        "\n",
        "# =============================\n",
        "# 4️⃣ HMM Evaluation (unchanged)\n",
        "# =============================\n",
        "start_time = time.time()\n",
        "hmm_preds = [viterbi(sent, transition_probs, emission_probs, tag_list) for sent in test_tokens]\n",
        "hmm_inference_time = time.time() - start_time\n",
        "\n",
        "evaluate_method(\"HMM\", test_tags, hmm_preds, inference_time=hmm_inference_time)\n",
        "print(\"Sample Misclassifications (HMM):\")\n",
        "for tok, true, pred in get_misclassifications(test_tags, hmm_preds, test_tokens):\n",
        "    print(\"TOKENS:\", tok)\n",
        "    print(\"TRUE:  \", true)\n",
        "    print(\"PRED:  \", pred)\n",
        "    print()\n",
        "\n",
        "# =============================\n",
        "# 5️⃣ Transformer (BERT) Evaluation (BIO)\n",
        "# =============================\n",
        "start_time = time.time()\n",
        "bert_preds = []\n",
        "for sent in test_tokens:\n",
        "    ents_raw = ner_pipeline(\" \".join(sent))  # list of dicts\n",
        "    ents = [(ent[\"word\"], ent[\"entity_group\"]) for ent in ents_raw]\n",
        "    pred_tags = to_bio_tags(sent, ents)\n",
        "    bert_preds.append(pred_tags)\n",
        "bert_inference_time = time.time() - start_time\n",
        "\n",
        "evaluate_method(\"Transformer (BERT)\", test_tags, bert_preds, inference_time=bert_inference_time)\n",
        "print(\"Sample Misclassifications (BERT):\")\n",
        "for tok, true, pred in get_misclassifications(test_tags, bert_preds, test_tokens):\n",
        "    print(\"TOKENS:\", tok)\n",
        "    print(\"TRUE:  \", true)\n",
        "    print(\"PRED:  \", pred)\n",
        "    print()\n",
        "\n",
        "# =============================\n",
        "# 6️⃣ BiLSTM-CRF Evaluation (unchanged)\n",
        "# =============================\n",
        "start_time = time.time()\n",
        "pred_tags_bilstm_final = []\n",
        "true_tags_bilstm_final = []\n",
        "for words, labels in test_loader:\n",
        "    preds = model(words)\n",
        "    pred_tags_bilstm_final.append([list(tag2idx.keys())[i] for i in preds[0]])\n",
        "    true_tags_bilstm_final.append([list(tag2idx.keys())[i.item()] for i in labels[0]])\n",
        "bilstm_inference_time = time.time() - start_time\n",
        "\n",
        "evaluate_method(\"BiLSTM-CRF\", true_tags_bilstm_final, pred_tags_bilstm_final, inference_time=bilstm_inference_time)\n",
        "print(\"Sample Misclassifications (BiLSTM-CRF):\")\n",
        "for tok, true, pred in get_misclassifications(true_tags_bilstm_final, pred_tags_bilstm_final, test_tokens):\n",
        "    print(\"TOKENS:\", tok)\n",
        "    print(\"TRUE:  \", true)\n",
        "    print(\"PRED:  \", pred)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aU6yFi6xbeKO"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# Named Entity Recognition (NER) Method Comparison\n",
        "# ================================================================\n",
        "\n",
        "# 1. Rule-Based NER\n",
        "# ------------------------------------------------\n",
        "# Pros:\n",
        "# - Extremely fast and requires no training data.\n",
        "# - Easy to understand and maintain for small, fixed domains.\n",
        "# - Works offline without heavy dependencies.\n",
        "#\n",
        "# Cons:\n",
        "# - Poor adaptability to new patterns or unseen entities.\n",
        "# - Requires constant manual updates to maintain accuracy.\n",
        "# - Limited generalization; struggles with complex linguistic variations.\n",
        "\n",
        "# 2. spaCy Pretrained Model\n",
        "# ------------------------------------------------\n",
        "# Pros:\n",
        "# - Good out-of-the-box performance for general-purpose NER.\n",
        "# - Fast inference speed with efficient implementation.\n",
        "# - Easy integration into Python pipelines.\n",
        "#\n",
        "# Cons:\n",
        "# - Requires retraining or fine-tuning for domain-specific terminology.\n",
        "# - May not capture niche entities without additional training data.\n",
        "# - Model size can still be relatively large for constrained environments.\n",
        "\n",
        "# 3. BiLSTM-CRF (from scratch)\n",
        "# ------------------------------------------------\n",
        "# Pros:\n",
        "# - Can be trained from scratch for any domain or language.\n",
        "# - CRF layer improves sequence labeling consistency.\n",
        "# - Highly customizable model architecture.\n",
        "#\n",
        "# Cons:\n",
        "# - Training requires large, labeled datasets.\n",
        "# - Slower training and inference compared to transformer-based models.\n",
        "# - Performance heavily depends on quality and size of training data.\n",
        "\n",
        "# 4. Transformer-Based Model (Hugging Face, e.g., BERT-based)\n",
        "# ------------------------------------------------\n",
        "# Pros:\n",
        "# - State-of-the-art accuracy in NER tasks across domains.\n",
        "# - Strong generalization due to large-scale pretraining.\n",
        "# - Easily fine-tuned for domain-specific use cases.\n",
        "#\n",
        "# Cons:\n",
        "# - Larger model size leads to higher memory and compute requirements.\n",
        "# - Slower inference compared to lightweight models.\n",
        "# - Requires GPU for efficient fine-tuning on large datasets.\n",
        "\n",
        "# ================================================================\n",
        "# Recommendation for Production Use:\n",
        "# ------------------------------------------------\n",
        "# If high accuracy and adaptability to various domains are priorities,\n",
        "# a transformer-based model (like BERT fine-tuned for NER) is recommended.\n",
        "# However, for resource-constrained environments or small-scale rule-bound tasks,\n",
        "# spaCy or rule-based approaches may be more practical.\n",
        "# ================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jTJb0Dzdysv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
